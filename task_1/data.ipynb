{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import warnings\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('dataset/')\n",
    "lm_filepath = os.path.join(data_dir+'/augmented_data', 'LM.csv')\n",
    "noise_filepath = os.path.join(data_dir+'/augmented_data', 'noise.csv')\n",
    "thesaurus_filepath = os.path.join(data_dir+'/augmented_data', 'thesaurus.csv')\n",
    "\n",
    "arguments_training_filepath = os.path.join(data_dir, 'arguments-training.tsv')\n",
    "arguments_validation_filepath = os.path.join(data_dir, 'arguments-validation.tsv')\n",
    "arguments_validation_filepath_zhihu = os.path.join(data_dir, 'arguments-validation-zhihu.tsv')\n",
    "arguments_test_filepath = os.path.join(data_dir, 'arguments-test.tsv')\n",
    "\n",
    "labels_training_filepath = os.path.join(data_dir, 'labels-training.tsv')\n",
    "labels_validation_filepath = os.path.join(data_dir, 'labels-validation.tsv')\n",
    "labels_validation_filepath_zhihu = os.path.join(data_dir, 'labels-validation-zhihu.tsv')\n",
    "labels_test_filepath = os.path.join(data_dir, 'labels-test.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGHER_ORDER_VALUES = ['Opennes to change', 'Self-transcendence', 'Conservation', 'Self-enhancement']\n",
    "\n",
    "HIGHER_ORDER_VALUES_AND_SUB = {'Opennes to change':['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism'], \n",
    "                       'Self-transcendence':['Humility', 'Benevolence: caring','Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity'], \n",
    "                       'Conservation':['Humility', 'Tradition','Conformity: interpresonal','Conformity: rules', 'Security: societal', 'Security: personal', 'Face'], \n",
    "                       'Self-enhancement':['Face', 'Power: dominance', 'Power: resources', 'Achievement', 'Hedonism']}\n",
    "\n",
    "\n",
    "LABELS = ['Self-direction thought', 'Self-direction action', 'Stimulation', 'Hedonism', 'Achievement', 'Power dominance', 'Power resources', 'Face', 'Security personal', 'Security societal', 'Tradition', 'Conformity rules', 'Conformity interpersonal', 'Humility', 'Benevolence caring', 'Benevolence dependability', 'Universalism concern', 'Universalism nature', 'Universalism tolerance', 'Universalism objectivity']\n",
    "PROMPT_FORMATS = [\"The premise: '{}' is '{}'. The conclusion is '{}'\\n. Question: Which value category does the argument belong to? Options: {} \\n\",\n",
    "                  \"Premise: {}\\nStance: {}\\nConclusion: {}. Value category: {}\\n Question: Which value category does the argument belong to?\\n\",\n",
    "                  \"Argument: {}. {}. {}. Value category: {}\\n Question: Which value category does the argument belong to?\\n\"]\n",
    "\n",
    "ENSEMBLE_PROMPT = [\"The premise '{}' is '{}'. The conclusion is '{}'. Which of the following higher order values does that support, there can be more than one option? Options: {}\\n\",\n",
    "                   \"The premise '{}' is '{}'. The conclusion is '{}'. This falls in the higher order value of '{}'. Which of the following value categories does that support? {}\\n\"]\n",
    "\n",
    "\n",
    "def convert_binary_labels_to_string(df):\n",
    "    label_names = df.columns[1:]\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        binary_values = row.values[1:]\n",
    "        string_labels = ''\n",
    "        for i, value in enumerate(binary_values):\n",
    "            if value == 1:\n",
    "                string_labels += label_names[i] + ', '\n",
    "        labels.append(string_labels[:-2])\n",
    "    return labels\n",
    "\n",
    "def ensemble_prompt_higher_order(df):\n",
    "    \"\"\"Creates an ensemble prompt for each argument with the first prompt format\"\"\"\n",
    "    \n",
    "    template = ENSEMBLE_PROMPT[0]\n",
    "    prompts = [\n",
    "                template.format(row['Premise'], row['Stance'], row['Conclusion'], ', '.join(HIGHER_ORDER_VALUES))\n",
    "                for _, row in df.iterrows()\n",
    "    ]\n",
    "    df['ensemble'] = prompts\n",
    "    return df\n",
    "\n",
    "\n",
    "def single_shot_prompt(df):\n",
    "    \"\"\"Creates a single shot prompt for each argument with the first prompt format\"\"\"\n",
    "    \n",
    "    template = PROMPT_FORMATS[0] # use the first template \n",
    "    prompts = [\n",
    "                template.format(row['Premise'], row['Stance'], row['Conclusion'], ', '.join(LABELS))\n",
    "                for _, row in df.iterrows()\n",
    "    ]\n",
    "    df['single_shot_prompt'] = prompts\n",
    "    return df\n",
    "\n",
    "def few_shot_prompt(df, num_shots=1, prompt_format=0, random_seed=46):\n",
    "    \"\"\"Creates a few shot prompt for each argument\"\"\"\n",
    "\n",
    "    prompt_format = PROMPT_FORMATS[prompt_format]\n",
    "    \n",
    "    selected_arguments = df.sample(n=num_shots, random_state=random_seed)\n",
    "    few_shot_prompts = [\n",
    "        # prompt_format.format(row['Premise'], row['Stance'], row['Conclusion'], ', '.join(LABELS)) + f\"Answer: {random.choice(LABELS)}\\n\"\n",
    "        prompt_format.format(row['Premise'], row['Stance'], row['Conclusion'], ', '.join(LABELS)) + f\"Answer: {', '.join(random.sample(LABELS, 2))}\\n\"\n",
    "        for _, row in selected_arguments.iterrows()\n",
    "    ]\n",
    "    df['few_shot_prompt'] = df.apply(lambda row: ''.join(few_shot_prompts) + prompt_format.format(row['Premise'], row['Stance'], row['Conclusion'], ', '.join(LABELS)) + f\"Answer: \\n\", axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# used for testing different prompt formats \n",
    "def prompt_formats(df):\n",
    "    prompts = [\n",
    "        [\n",
    "            prompt.format(row['Premise'], row['Stance'], row['Conclusion'], ', '.join(LABELS))\n",
    "            for prompt in PROMPT_FORMATS\n",
    "        ]\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    df['prompt_formats'] = prompts\n",
    "    return df\n",
    "\n",
    "def labels_to_multi_choice():\n",
    "    \"\"\"Converts the labels to a multi choice format\"\"\"\n",
    "    multi_choice_format = \"{}: {}\"\n",
    "    multi_choice_options = []\n",
    "\n",
    "    for index, label in enumerate(LABELS):\n",
    "        multi_choice_option = multi_choice_format.format(chr(65 + index), label)\n",
    "        multi_choice_options.append(multi_choice_option)\n",
    "\n",
    "    return multi_choice_options\n",
    "\n",
    "def label_to_vector(df):\n",
    "    \"\"\"Converts the labels to a vector\"\"\"\n",
    "    label_names = df.iloc[:, 1:]\n",
    "    return label_names.values.tolist()\n",
    "\n",
    "def add_labels_to_augmented_data(augmented_df, original_df):\n",
    "    \"\"\"add the label_vector and label_string of the original data to the augmented data by matching the Argument ID\"\"\"\n",
    "    augmented_df['label_vector'] = augmented_df['Argument ID'].map(original_df.set_index('Argument ID')['label_vector'])\n",
    "    augmented_df['label_string'] = augmented_df['Argument ID'].map(original_df.set_index('Argument ID')['label_string'])\n",
    "    return augmented_df\n",
    "    # augmented_df['Labels'] = augmented_df['Argument ID'].map(original_df.set_index('Argument ID')['label_vector'])\n",
    "    # return augmented_df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(arguments_training_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "# train_augmented = pd.read_csv(arguments_training_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "\n",
    "validation = pd.read_csv(arguments_validation_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "validation_zhihu = pd.read_csv(arguments_validation_filepath_zhihu, encoding='utf-8', sep='\\t', header=0)\n",
    "test = pd.read_csv(arguments_test_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "\n",
    "labels_training = pd.read_csv(labels_training_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "labels_validation = pd.read_csv(labels_validation_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "labels_validation_zhihu = pd.read_csv(labels_validation_filepath_zhihu, encoding='utf-8', sep='\\t', header=0)\n",
    "labels_test = pd.read_csv(labels_test_filepath, encoding='utf-8', sep='\\t', header=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add vector labels to the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01001</td>\n",
       "      <td>Entrapment should be legalized</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>if entrapment can serve to more easily capture...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01003</td>\n",
       "      <td>We should abandon marriage</td>\n",
       "      <td>against</td>\n",
       "      <td>marriage is the ultimate commitment to someone...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01004</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>against</td>\n",
       "      <td>it provides a useful income for some people</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                      Conclusion       Stance  \\\n",
       "0      A01001  Entrapment should be legalized  in favor of   \n",
       "1      A01002     We should ban human cloning  in favor of   \n",
       "2      A01003      We should abandon marriage      against   \n",
       "3      A01004       We should ban naturopathy      against   \n",
       "4      A01005         We should ban fast food  in favor of   \n",
       "\n",
       "                                             Premise  \\\n",
       "0  if entrapment can serve to more easily capture...   \n",
       "1  we should ban human cloning as it will only ca...   \n",
       "2  marriage is the ultimate commitment to someone...   \n",
       "3        it provides a useful income for some people   \n",
       "4  fast food should be banned because it is reall...   \n",
       "\n",
       "                                        label_vector  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label_vector'] = label_to_vector(labels_training)\n",
    "validation['label_vector'] = label_to_vector(labels_validation)\n",
    "validation_zhihu['label_vector'] = label_to_vector(labels_validation_zhihu)\n",
    "test['label_vector'] = label_to_vector(labels_test)\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the data and labels into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label_string'] = convert_binary_labels_to_string(labels_training)\n",
    "validation['label_string'] = convert_binary_labels_to_string(labels_validation)\n",
    "validation_zhihu['label_string'] = convert_binary_labels_to_string(labels_validation_zhihu)\n",
    "test['label_string'] = convert_binary_labels_to_string(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>label_vector</th>\n",
       "      <th>label_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030</td>\n",
       "      <td>A20376</td>\n",
       "      <td>Holocaust denial should be considered a crimin...</td>\n",
       "      <td>against</td>\n",
       "      <td>the holocaust is an unproven event and anyone ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>Self-direction: thought, Security: personal, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2030</td>\n",
       "      <td>A20376</td>\n",
       "      <td>Holocaust denial should be a criminal offence</td>\n",
       "      <td>against</td>\n",
       "      <td>the holocaust is a clearly documented event an...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>Self-direction: thought, Security: personal, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>2030</td>\n",
       "      <td>A20376</td>\n",
       "      <td>Holocaust denial should be a criminal offence</td>\n",
       "      <td>against</td>\n",
       "      <td>anyone who denies its existence can be easily ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>Self-direction: thought, Security: personal, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>2030</td>\n",
       "      <td>A20376</td>\n",
       "      <td>Holocaust denial should be a criminal offence.</td>\n",
       "      <td>against</td>\n",
       "      <td>the holocaust is clearly documented in writing...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>Self-direction: thought, Security: personal, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23285</th>\n",
       "      <td>2030</td>\n",
       "      <td>A20376</td>\n",
       "      <td>Holocaust denial should be a felony.</td>\n",
       "      <td>against</td>\n",
       "      <td>the holocaust is clearly documented. anyone wh...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>Self-direction: thought, Security: personal, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23302</th>\n",
       "      <td>2030</td>\n",
       "      <td>A20376</td>\n",
       "      <td>Holocaust denial should be considered a crimin...</td>\n",
       "      <td>against</td>\n",
       "      <td>the holocaust is a clear evidence of its exist...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>Self-direction: thought, Security: personal, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32842</th>\n",
       "      <td>2030</td>\n",
       "      <td>A20376</td>\n",
       "      <td>Holocaust denial should be a criminal offense.</td>\n",
       "      <td>against</td>\n",
       "      <td>the holocaust is a well documented event. anyo...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>Self-direction: thought, Security: personal, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33015</th>\n",
       "      <td>2030</td>\n",
       "      <td>A20376</td>\n",
       "      <td>Holocaust denial should be a criminal offence.</td>\n",
       "      <td>against</td>\n",
       "      <td>the holocaust is clearly documented and anyone...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>Self-direction: thought, Security: personal, H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 Argument ID  \\\n",
       "0            2030      A20376   \n",
       "265          2030      A20376   \n",
       "1168         2030      A20376   \n",
       "14297        2030      A20376   \n",
       "23285        2030      A20376   \n",
       "23302        2030      A20376   \n",
       "32842        2030      A20376   \n",
       "33015        2030      A20376   \n",
       "\n",
       "                                              Conclusion   Stance  \\\n",
       "0      Holocaust denial should be considered a crimin...  against   \n",
       "265        Holocaust denial should be a criminal offence  against   \n",
       "1168       Holocaust denial should be a criminal offence  against   \n",
       "14297     Holocaust denial should be a criminal offence.  against   \n",
       "23285               Holocaust denial should be a felony.  against   \n",
       "23302  Holocaust denial should be considered a crimin...  against   \n",
       "32842     Holocaust denial should be a criminal offense.  against   \n",
       "33015     Holocaust denial should be a criminal offence.  against   \n",
       "\n",
       "                                                 Premise  \\\n",
       "0      the holocaust is an unproven event and anyone ...   \n",
       "265    the holocaust is a clearly documented event an...   \n",
       "1168   anyone who denies its existence can be easily ...   \n",
       "14297  the holocaust is clearly documented in writing...   \n",
       "23285  the holocaust is clearly documented. anyone wh...   \n",
       "23302  the holocaust is a clear evidence of its exist...   \n",
       "32842  the holocaust is a well documented event. anyo...   \n",
       "33015  the holocaust is clearly documented and anyone...   \n",
       "\n",
       "                                            label_vector  \\\n",
       "0      [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "265    [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "1168   [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "14297  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "23285  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "23302  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "32842  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "33015  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "\n",
       "                                            label_string  \n",
       "0      Self-direction: thought, Security: personal, H...  \n",
       "265    Self-direction: thought, Security: personal, H...  \n",
       "1168   Self-direction: thought, Security: personal, H...  \n",
       "14297  Self-direction: thought, Security: personal, H...  \n",
       "23285  Self-direction: thought, Security: personal, H...  \n",
       "23302  Self-direction: thought, Security: personal, H...  \n",
       "32842  Self-direction: thought, Security: personal, H...  \n",
       "33015  Self-direction: thought, Security: personal, H...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = pd.read_csv(lm_filepath)\n",
    "noise = pd.read_csv(noise_filepath)\n",
    "thesaurus = pd.read_csv(thesaurus_filepath)\n",
    "\n",
    "lm = add_labels_to_augmented_data(lm, train)\n",
    "noise = add_labels_to_augmented_data(noise, train)\n",
    "thesaurus = add_labels_to_augmented_data(thesaurus, train)\n",
    "# print lm where aurgment id is A20376\n",
    "lm[lm['Argument ID'] == 'A20376']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Argument ID'] == 'A20376']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add higher level labels to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_order_values_df = pd.DataFrame(columns=['higher_order_value', 'value_category'])\n",
    "for higher_order_value in HIGHER_ORDER_VALUES_AND_SUB:\n",
    "    for value_category in HIGHER_ORDER_VALUES_AND_SUB[higher_order_value]:\n",
    "        higher_order_values_df = higher_order_values_df.append({'higher_order_value': higher_order_value, 'value_category': value_category}, ignore_index=True)\n",
    "\n",
    "# higher_order_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the higher order values to the labels of the training, validation and test set\n",
    "# def add_higher_order_values(df):\n",
    "#     df['higher_order_value'] = df['label_string'].apply(lambda x: higher_order_values_df[higher_order_values_df['value_category'].isin(x)]['higher_order_value'].unique())\n",
    "#     return df\n",
    "\n",
    "# train = add_higher_order_values(train)\n",
    "# validation = add_higher_order_values(validation)\n",
    "# validation_zhihu = add_higher_order_values(validation_zhihu)\n",
    "# test = add_higher_order_values(test)\n",
    "\n",
    "# train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add promts to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = single_shot_prompt(train)\n",
    "train = few_shot_prompt(train, num_shots=1, prompt_format=0, random_seed=46)\n",
    "train = ensemble_prompt_higher_order(train) # \n",
    "noise = single_shot_prompt(noise)\n",
    "\n",
    "noise.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select 10 random samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10 = train.sample(10)\n",
    "train_10.iloc[0]['single_shot_prompt']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_from_list(query):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "for index, row in train_10.iterrows():\n",
    "    result = query_from_list(row['single_shot_prompt'])\n",
    "    print(f\"Prompt: {row['single_shot_prompt']} \\n Prediction: {result[0]}\\n True Label: {row['label_string']}\\n\")\n",
    "    print(60*'-')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_10.iterrows():\n",
    "    result = query_from_list(row['few_shot_prompt'])\n",
    "    print(f\"{row['few_shot_prompt']:<24} {result[0]}\\n True Label: {row['label_string']}\\n\")\n",
    "    # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt ensemble for higher order values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_10.iterrows():\n",
    "    result = query_from_list(row['ensemble'])\n",
    "    print(f\"Prompt1:\\t{row['ensemble']} Prediction higher_order_value:\\t {result[0]}\\n True higher_order_value:\\t{row['higher_order_value']}\")\n",
    "    # template = \"The premise '{}' is '{}'. The conclusion is '{}'. This falls in the higher order value of '{}'. Which of the following value categories does that support? {}\\n\"\n",
    "    template = ENSEMBLE_PROMPT[1]\n",
    "    values = HIGHER_ORDER_VALUES_AND_SUB[result[0]]\n",
    "    prompt = template.format(row['Premise'], row['Stance'], row['Conclusion'], result[0], values)\n",
    "    result = query_from_list(prompt)\n",
    "    print(f\"Prompt2:\\t {prompt}Predicted value category:\\t {result[0]}\\n True value category:\\t {row['label_string']}\\n\")\n",
    "    print(10*'-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 2030,\n",
       " 'Argument ID': 'A20376',\n",
       " 'Conclusion': 'Holocaust denial should be considered a criminal offence.',\n",
       " 'Stance': 'against',\n",
       " 'Premise': \"the holocaust is an unproven event and anyone who denies it's existence can be easily disproven so money and time should not be wasted on criminalizing it and creating laws.\",\n",
       " 'label_vector': [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       " 'label_string': 'Self-direction: thought, Security: personal, Humility, Universalism: objectivity',\n",
       " 'single_shot_prompt': \"The premise: 'the holocaust is an unproven event and anyone who denies it's existence can be easily disproven so money and time should not be wasted on criminalizing it and creating laws.' is 'against'. The conclusion is 'Holocaust denial should be considered a criminal offence.'\\n. Question: Which value category does the argument belong to? Options: Self-direction thought, Self-direction action, Stimulation, Hedonism, Achievement, Power dominance, Power resources, Face, Security personal, Security societal, Tradition, Conformity rules, Conformity interpersonal, Humility, Benevolence caring, Benevolence dependability, Universalism concern, Universalism nature, Universalism tolerance, Universalism objectivity \\n\",\n",
       " 'few_shot_prompt': \"The premise: 'we need to subsidize space exploration so we can find somewhere for the human race to go when we finally stop destroying our planet.' is 'in favor of'. The conclusion is 'We should subsidize space exploration.'\\n. Question: Which value category does the argument belong to? Options: Self-direction thought, Self-direction action, Stimulation, Hedonism, Achievement, Power dominance, Power resources, Face, Security personal, Security societal, Tradition, Conformity rules, Conformity interpersonal, Humility, Benevolence caring, Benevolence dependability, Universalism concern, Universalism nature, Universalism tolerance, Universalism objectivity \\nAnswer: Tradition, Power resources\\nThe premise: 'the holocaust is an unproven event and anyone who denies it's existence can be easily disproven so money and time should not be wasted on criminalizing it and creating laws.' is 'against'. The conclusion is 'Holocaust denial should be considered a criminal offence.'\\n. Question: Which value category does the argument belong to? Options: Self-direction thought, Self-direction action, Stimulation, Hedonism, Achievement, Power dominance, Power resources, Face, Security personal, Security societal, Tradition, Conformity rules, Conformity interpersonal, Humility, Benevolence caring, Benevolence dependability, Universalism concern, Universalism nature, Universalism tolerance, Universalism objectivity \\nAnswer: \\n\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "dataset_path = '../datasets/touche23_prompt'\n",
    "dataset = load_from_disk(dataset_path)\n",
    "dataset['augmented_lm'][0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
