{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(example):\n",
    "    example[\"Labels\"] = [i for i in ast.literal_eval(example[\"Labels\"])]\n",
    "    return example\n",
    "\n",
    "valueeval23 = load_dataset(\"webis/Touche23-ValueEval\")\n",
    "training_dataset = valueeval23[\"training\"].map(convert_labels)\n",
    "validation_dataset = valueeval23[\"validation\"].map(convert_labels)\n",
    "training_dataset['Labels']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from local files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data')\n",
    "arguments_training_filepath = os.path.join(data_dir, 'arguments-training.tsv')\n",
    "arguments_validation_filepath = os.path.join(data_dir, 'arguments-validation.tsv')\n",
    "arguments_validation_filepath_zhihu = os.path.join(data_dir, 'arguments-validation-zhihu.tsv')\n",
    "arguments_test_filepath = os.path.join(data_dir, 'arguments-test.tsv')\n",
    "\n",
    "labels_training_filepath = os.path.join(data_dir, 'labels-training.tsv')\n",
    "labels_validation_filepath = os.path.join(data_dir, 'labels-validation.tsv')\n",
    "labels_validation_filepath_zhihu = os.path.join(data_dir, 'labels-validation-zhihu.tsv')\n",
    "labels_test_filepath = os.path.join(data_dir, 'labels-test.tsv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument ID                                               A01001\n",
      "Conclusion                        Entrapment should be legalized\n",
      "Stance                                               in favor of\n",
      "Premise        if entrapment can serve to more easily capture...\n",
      "Name: 0, dtype: object \n",
      " Argument ID                   A01001\n",
      "Self-direction: thought            0\n",
      "Self-direction: action             0\n",
      "Stimulation                        0\n",
      "Hedonism                           0\n",
      "Achievement                        0\n",
      "Power: dominance                   0\n",
      "Power: resources                   0\n",
      "Face                               0\n",
      "Security: personal                 0\n",
      "Security: societal                 1\n",
      "Tradition                          0\n",
      "Conformity: rules                  0\n",
      "Conformity: interpersonal          0\n",
      "Humility                           0\n",
      "Benevolence: caring                0\n",
      "Benevolence: dependability         0\n",
      "Universalism: concern              0\n",
      "Universalism: nature               0\n",
      "Universalism: tolerance            0\n",
      "Universalism: objectivity          0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "arguments_training = pd.read_csv(arguments_training_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "arguments_validation = pd.read_csv(arguments_validation_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "arguments_validation_zhihu = pd.read_csv(arguments_validation_filepath_zhihu, encoding='utf-8', sep='\\t', header=0)\n",
    "arguments_test = pd.read_csv(arguments_test_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "\n",
    "\n",
    "labels_training = pd.read_csv(labels_training_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "labels_validation = pd.read_csv(labels_validation_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "labels_validation_zhihu = pd.read_csv(labels_validation_filepath_zhihu, encoding='utf-8', sep='\\t', header=0)\n",
    "labels_test = pd.read_csv(labels_test_filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "\n",
    "\n",
    "print(arguments_training.iloc[0], '\\n', labels_training.iloc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_labels_to_string(df):\n",
    "    label_names = df.columns[1:]\n",
    "    string_labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        binary_values = row.values[1:]\n",
    "        string_labels.append([label_names[i] for i, value in enumerate(binary_values) if value == 1])\n",
    "\n",
    "    df['String Labels'] = string_labels\n",
    "    return df\n",
    "\n",
    "def preprocess_arguments(df):\n",
    "    prompt_format = \"The premise: {}, is {}, the conclusion is {}. Which value category does it support?\\n\"\n",
    "    preprocessed_arguments = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        premise = row['Premise']\n",
    "        stance = row['Stance']\n",
    "        conclusion = row['Conclusion']\n",
    "        prompt = prompt_format.format(premise, stance, conclusion)\n",
    "        preprocessed_arguments.append(prompt)\n",
    "        \n",
    "    return preprocessed_arguments\n",
    "\n",
    "def combine_columns(df_arguments, df_labels):\n",
    "    \"\"\"Combines the two `DataFrames` on column `Argument ID`\"\"\"\n",
    "    return pd.merge(df_arguments, df_labels, on='Argument ID')\n",
    "\n",
    "def generate_prompts(df):\n",
    "    input_prompts = []\n",
    "    output_prompts = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        input_text = row['Text']\n",
    "        labels = row['Labels']\n",
    "\n",
    "        # Generate the input and output prompts\n",
    "        input_prompt = \"Text: {}\".format(input_text)\n",
    "        output_prompt = \"Label: {}\".format(labels)\n",
    "\n",
    "        input_prompts.append(input_prompt)\n",
    "        output_prompts.append(output_prompt)\n",
    "\n",
    "    return input_prompts, output_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The premise: if entrapment can serve to more easily capture wanted criminals, then why shouldn't it be legal?, is in favor of, the conclusion is Entrapment should be legalized. Which value category does it support?\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_arguments = preprocess_arguments(arguments_training)\n",
    "processed_arguments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Security: personal', 'Benevolence: caring', 'Universalism: concern']\n"
     ]
    }
   ],
   "source": [
    "converted_labels = convert_binary_labels_to_string(labels_training)\n",
    "print(converted_labels['String Labels'].iloc[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument ID                                               A01002\n",
      "Conclusion                           We should ban human cloning\n",
      "Stance                                               in favor of\n",
      "Premise        we should ban human cloning as it will only ca...\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The premise: we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same. is in favor of conclusion: We should ban human cloning. Which value category does it support? \\n (A) societal (B) rules (C) interpersonal (D) none of the above'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argument = arguments_training.iloc[1]\n",
    "print(argument)\n",
    "sample = f\"The premise: {argument['Premise']} is {argument['Stance']} conclusion: {argument['Conclusion']}. Which value category does it support? \\n (A) societal (B) rules (C) interpersonal (D) none of the above\"\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The premise: we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same., is in favor of, the conclusion is We should ban human cloning. Which value category does it support?\\n (A) societal (B) rules (C) interpersonal (D) none of the above'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argument = processed_arguments[1]\n",
    "argument = f\"{argument} (A) societal (B) rules (C) interpersonal (D) none of the above\"\n",
    "argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 12:15:55.127038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List\n",
    "from transformers import pipeline\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text2text-generation\", model=\"allenai/unifiedqa-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'societal'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(argument)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
